import requests
import pandas as pd
import time
import json
import re
from urllib.parse import quote
import math

# ========== é…ç½® ==========
LIBRARY_ID = "sapln-adelaide"
BASE_URL = f"https://thunder.api.overdrive.com/v2/libraries/{LIBRARY_ID}/media"
CLIENT_ID = "dewey"

# ========== å·¥å…·å‡½æ•° ==========
def normalize(text):
    """æ ‡å‡†åŒ–å­—ç¬¦ä¸²ï¼šå»æ‰æ ‡ç‚¹ã€å¤§å°å†™"""
    if not isinstance(text, str):
        return ""
    return re.sub(r"[^\w\s]", "", text).strip().lower()
    
def get_format_names(item):
    names = []
    for f in item.get("formats", []) or []:
        if isinstance(f, dict):
            names.append(f.get("name", ""))
        elif isinstance(f, str):
            names.append(f)
    return names

def detect_media_type(format_names):
    joined = " | ".join(format_names).lower()
    if "audiobook" in joined:
        return "æœ‰å£°ä¹¦"
    if "ebook" in joined or "read" in joined or "kobo" in joined or "kindle" in joined:
        return "ç”µå­ä¹¦"
    return "æœªçŸ¥"

def extract_availability_fields(item):
    """
    åŒæ—¶å…¼å®¹ä¸¤ç§å¯èƒ½ç»“æ„ï¼š
    1) å¹³é“ºåœ¨é¡¶å±‚ï¼šcopiesOwned / copiesAvailable / numberOfHolds / availabilityType / estimatedWaitDays
    2) åµŒå¥—åœ¨ item['availability'] é‡Œ
    å¹¶è¡¥å…… isAvailable, isHoldable, luckyDayAvailableCopies å­—æ®µ
    """
    avail = item.get("availability", {}) or {}

    def pick(k, default=None):
        return avail.get(k, item.get(k, default))

    fields = {
        "availabilityType": item.get("availabilityType", avail.get("availabilityType")),
        "copiesOwned": pick("copiesOwned", 0) or 0,
        "copiesAvailable": pick("copiesAvailable", 0) or 0,
        "numberOfHolds": pick("numberOfHolds", 0) or 0,
        "estimatedWaitDays": pick("estimatedWaitDays", None),
        "isAvailable": item.get("isAvailable", avail.get("isAvailable", False)),
        "isHoldable": item.get("isHoldable", avail.get("isHoldable", True)),
        "luckyDayAvailableCopies": item.get("luckyDayAvailableCopies", avail.get("luckyDayAvailableCopies", 0)),
    }
    return fields

def compute_wait_weeks(copies_owned, holds, estimated_wait_days):
    if estimated_wait_days is not None:
        try:
            return max(1, round(float(estimated_wait_days) / 7))
        except Exception:
            pass
    if copies_owned and copies_owned > 0:
        # ç²—ç•¥ä¼°ç®—ï¼šæ¯æœ¬ä¸¤å‘¨ï¼›(æ’é˜Ÿäººæ•°+ç°æœ‰æœ¬æ•°)/æœ¬æ•° * 2 å‘¨
        return max(1, round((holds + copies_owned) / copies_owned * 2))
    return None

def search_libby_by_title(title):
    """åœ¨ OverDrive (Libby) æœç´¢ä¹¦å"""
    url = f"{BASE_URL}?query={quote(title)}&format=ebook-overdrive,ebook-media-do,ebook-overdrive-provisional,audiobook-overdrive,audiobook-overdrive-provisional,magazine-overdrive&perPage=24&page=1&x-client-id={CLIENT_ID}"
    try:
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            return response.json().get("items", [])
        else:
            print(f"âš ï¸ æœç´¢å¤±è´¥: {title} -> {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {title} -> {e}")
        return []

import math

def get_book_availability(item):
    """
    æ¯è¡ŒåŒ…å« Title, Author, Availability, MediaType, ç­‰å¾…æƒ…å†µ
    ä¼˜åŒ–å€Ÿé˜…çŠ¶æ€åˆ¤æ–­ï¼Œç»¼åˆ isAvailable, isHoldable, luckyDayAvailableCopies
    """
    results = []

    # ä¹¦å
    raw_title = item.get("title", "æœªçŸ¥ä¹¦å")
    title = raw_title.get("main") if isinstance(raw_title, dict) else raw_title

    # ä½œè€…
    creators = item.get("creators") or []
    author = ", ".join([c.get("name", "") for c in creators if isinstance(c, dict)])

    # æ‰€æœ‰æ ¼å¼
    format_names = get_format_names(item)
    if not format_names:
        format_names = ["æœªçŸ¥æ ¼å¼"]

    # è·å–å¯ç”¨æ€§å­—æ®µ
    av = extract_availability_fields(item)

    # æŒ‰åª’ä½“ç±»å‹åˆ†ç»„
    grouped_formats = {"ç”µå­ä¹¦": [], "æœ‰å£°ä¹¦": [], "æœªçŸ¥": []}
    for fmt in format_names:
        media_type = detect_media_type([fmt])
        grouped_formats[media_type].append(fmt)

    # éå†æ¯ä¸ªåª’ä½“ç±»å‹
    for media_type, formats in grouped_formats.items():
        if not formats:
            continue

        # ç»¼åˆåˆ¤æ–­å¯å€ŸçŠ¶æ€
        if av["isAvailable"] or av["copiesAvailable"] > 0 or av["luckyDayAvailableCopies"] > 0:
            wait_text = "å¯ç«‹å³å€Ÿé˜…"
            availability = "æœ‰"
        elif not av["isHoldable"]:
            wait_text = "ä¸å¯å€Ÿ"
            availability = "æ²¡æœ‰"
        elif av["estimatedWaitDays"] is not None:
            try:
                wait_weeks = max(1, round(float(av["estimatedWaitDays"]) / 7))
                wait_text = f"ç­‰å¾…çº¦ {wait_weeks} å‘¨"
                availability = "æ²¡æœ‰"
            except Exception:
                wait_text = "ä¸å¯å€Ÿ"
                availability = "æ²¡æœ‰"
        else:
            wait_text = "ä¸å¯å€Ÿ"
            availability = "æ²¡æœ‰"

        results.append({
            "Title": title,
            "Author": author,
            "Availability": availability,
            "MediaType": media_type,
            "ç­‰å¾…æƒ…å†µ": wait_text
        })

    return results

def preprocess_title(title):
    """åªä¿ç•™æ‹¬å· ( æˆ–å†’å· : ä¹‹å‰çš„éƒ¨åˆ†"""
    if not isinstance(title, str):
        return ""
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ª ( æˆ– : çš„ä½ç½®
    idx1 = title.find('(')
    idx2 = title.find(':')
    idx = min(idx1 if idx1 != -1 else len(title), idx2 if idx2 != -1 else len(title))
    return title[:idx].strip()

def find_all_matches(items, title, author):
    """
    ä¹¦åå®Œå…¨åŒ¹é…ï¼Œä½œè€…ååŒ…å«å³å¯
    """
    title_norm = normalize(preprocess_title(title))
    author_norm = normalize(author)
    matches = []

    for item in items:
        raw_title = item.get("title", "")
        item_title = raw_title.get("main") if isinstance(raw_title, dict) else raw_title
        item_title_norm = normalize(preprocess_title(item_title))
        creators = item.get("creators") or []
        item_authors = " ".join([c.get("name", "") for c in creators if isinstance(c, dict)])
        item_author_norm = normalize(item_authors)
        # ä¹¦åå®Œå…¨åŒ¹é…ï¼Œä½œè€…ååŒ…å«å³å¯
        if title_norm == item_title_norm and author_norm in item_author_norm:
            matches.append(item)
    return matches

def debug_probe(title, author=None, limit=5):
    """
    æ‰“å°åŸå§‹è¿”å›é‡Œçš„å…³é”®å­—æ®µï¼Œç¡®è®¤æ˜¯å¦æ‹¿åˆ° copiesAvailable / numberOfHolds / copiesOwned ç­‰ã€‚
    """
    print(f"\n==== DEBUG PROBE for: {title} ====")
    items = search_libby_by_title(title)
    if not items:
        print("æ— è¿”å› items")
        return

    # åªçœ‹å‰å‡ æ¡ï¼Œé¿å…åˆ·å±
    for idx, it in enumerate(items[:limit], 1):
        # ä¹¦å
        raw_title = it.get("title", "")
        tname = raw_title.get("main") if isinstance(raw_title, dict) else raw_title

        # ä½œè€…
        creators = it.get("creators") or []
        creator_names = ", ".join([c.get("name", "") for c in creators if isinstance(c, dict)]) or it.get("firstCreatorName", "")

        # å…³é”®é”®æ˜¯å¦å­˜åœ¨
        keys = set(it.keys())
        has_av_nested = isinstance(it.get("availability"), dict)
        av = extract_availability_fields(it)

        # æ‰“å°
        print(f"\n-- ITEM {idx} --")
        print("Title:", tname)
        print("Author(s):", creator_names)
        print("Keys:", sorted(list(keys)))
        print("Formats:", get_format_names(it))
        print("MediaType (detected):", detect_media_type(get_format_names(it)))
        print("Top-level availabilityType:", it.get("availabilityType"))
        print("Has nested 'availability' dict?:", has_av_nested)
        if has_av_nested:
            print("Nested availability keys:", list(it.get("availability", {}).keys()))

        print("copiesOwned:", av["copiesOwned"])
        print("copiesAvailable:", av["copiesAvailable"])
        print("numberOfHolds:", av["numberOfHolds"])
        print("estimatedWaitDays:", av["estimatedWaitDays"])


# ========== ä¸»ç¨‹åº ==========
def search_books_in_libby(csv_path):
    # è¯»å– CSV æ–‡ä»¶ï¼ˆGoodreads å¯¼å‡ºæ˜¯é€—å·åˆ†éš”ï¼‰
    try:
        df = pd.read_csv(csv_path, sep=",", dtype=str, encoding="utf-8")
    except Exception as e:
        print(f"âŒ CSV è¯»å–å¤±è´¥: {e}")
        return

    # æ£€æŸ¥æ˜¯å¦æœ‰ Titleã€Authorã€Exclusive Shelf åˆ—
    if "Title" not in df.columns or "Author" not in df.columns or "Exclusive Shelf" not in df.columns:
        print("âŒ é”™è¯¯ï¼šCSV æ–‡ä»¶ä¸­ç¼ºå°‘ Titleã€Author æˆ– Exclusive Shelf åˆ—ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼")
        print(f"å¯ç”¨åˆ—ï¼š{df.columns.tolist()}")
        return

    # åªå¤„ç† to-read
    df = df[df["Exclusive Shelf"].str.strip().str.lower() == "to-read"]

    results = []

    for idx, row in df.iterrows():
        title = str(row["Title"]).strip()
        author = str(row["Author"]).strip()
        print(f"\nğŸ” å¼€å§‹æŸ¥è¯¢: {title} by {author}")

        items = search_libby_by_title(preprocess_title(title))
        matches = find_all_matches(items, title, author)

        # æŒ‰ title åˆ†ç»„ï¼Œåˆå¹¶åŒä¸€æœ¬ä¹¦çš„ä¸åŒåª’ä½“ç±»å‹
        media_map = {}
        for it in matches:
            raw_title = it.get("title", "")
            item_title = raw_title.get("main") if isinstance(raw_title, dict) else raw_title
            key = normalize(preprocess_title(item_title))
            if key not in media_map:
                media_map[key] = []
            media_map[key].append(it)

        if media_map:
            for key, items_group in media_map.items():
                for it in items_group:
                    book_infos = get_book_availability(it)
                    for info in book_infos:
                        # åªä¿ç•™ Titleã€Authorã€Availabilityã€MediaTypeã€ç­‰å¾…æƒ…å†µ
                        results.append({
                            "Title": f"{info['Title']} ({info['Author']})",
                            "Availability": info["Availability"],
                            "MediaType": info["MediaType"],
                            "ç­‰å¾…æƒ…å†µ": info["ç­‰å¾…æƒ…å†µ"]
                        })
                        print(f"âœ… æ‰¾åˆ°: {info['Title']} | ä½œè€…: {info['Author']} | ç±»å‹: {info['MediaType']} | çŠ¶æ€: {info['ç­‰å¾…æƒ…å†µ']}")
        else:
            results.append({
                "Title": f"{title}",
                "Availability": "æœªæ‰¾åˆ°",
                "MediaType": "æœªæ‰¾åˆ°",
                "ç­‰å¾…æƒ…å†µ": "æœªæ‰¾åˆ°"
            })
            print(f"âŒ æœªæ‰¾åˆ°: {title}")

        time.sleep(1)  # é˜²æ­¢è¢«å°

    result_df = pd.DataFrame(results)
    result_df.to_csv("libby_search_results.csv", index=False)
    print("\nâœ… æŸ¥è¯¢å®Œæˆï¼ç»“æœå·²å¯¼å‡ºåˆ° libby_search_results.csv")
    return result_df

# ========== æ‰§è¡Œ ==========
if __name__ == "__main__":
    # å…ˆåšæ¢é’ˆï¼ŒéªŒè¯å­—æ®µæ˜¯å¦æ‹¿åˆ°
    #debug_probe("Tell Me What You Did", author="Carter Wilson", limit=10)
    #debug_probe("Welcome to the Hyunam-Dong Bookshop", author="Hwang Bo-Reum", limit=10)

    # å†è·‘ä½ åŸæ¥çš„æ‰¹é‡æµç¨‹
    search_books_in_libby("goodreads_export.csv")

